{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "path = Path(\"C:/Users/shaur/Desktop/Glean_Implementation\")\n",
    "sys.path.append(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.config' from 'C:\\\\Users\\\\shaur\\\\Desktop\\\\Glean_Implementation\\\\utils\\\\config.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from utils import Neighbour, config, preprocess\n",
    "import cv2\n",
    "import traceback\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import importlib\n",
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_vocab(path):\n",
    "    cached_data = pickle.load(open(path, 'rb'))\n",
    "    return cached_data['vocab'], cached_data['mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(annotations, fields_dict, n_neighbours=5, vocabulary=None):\n",
    "    \"\"\"Generates input samples from annotations data.\"\"\"\n",
    "    field_ids = list()\n",
    "    candidate_cords = list()\n",
    "    neighbours = list()\n",
    "    neighbour_cords = list()\n",
    "    n_classes = len(fields_dict)\n",
    "    for field, value in annotations.items():\n",
    "        if annotations[field]:\n",
    "            for idx, val in enumerate(value):\n",
    "                _neighbours, _neighbour_cords = preprocess.get_neighbours(\n",
    "                    val['neighbours'],\n",
    "                    vocabulary, n_neighbours\n",
    "                )\n",
    "                field_ids.append(np.eye(n_classes)[fields_dict[field]])\n",
    "                candidate_cords.append(\n",
    "                    [\n",
    "                        val['x'],\n",
    "                        val['y']\n",
    "                    ]\n",
    "                )\n",
    "                neighbours.append(_neighbours)\n",
    "                neighbour_cords.append(_neighbour_cords)\n",
    "    return torch.Tensor(field_ids).type(torch.FloatTensor), torch.Tensor(candidate_cords).type(\n",
    "        torch.FloatTensor), torch.Tensor(neighbours).type(torch.int64), torch.Tensor(neighbour_cords).type(\n",
    "        torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_coordinates(annotations, width, height):\n",
    "    try:\n",
    "        for cls, cads in annotations.items():\n",
    "            for i, cd in enumerate(cads):\n",
    "                cd = cd.copy()\n",
    "                x1 = cd['x1']\n",
    "                y1 = cd['y1']\n",
    "                x2 = cd['x2']\n",
    "                y2 = cd['y2']\n",
    "                cd['x'] = ((x1 + x2) / 2) / width\n",
    "                cd['y'] = ((y1 + y2) / 2) / height\n",
    "                neighbours = []\n",
    "                for neh in cd['neighbours']:\n",
    "                    neh = neh.copy()\n",
    "                    x1_neh = neh['x1']\n",
    "                    y1_neh = neh['y1']\n",
    "                    x2_neh = neh['x2']\n",
    "                    y2_neh = neh['y2']\n",
    "                    # calculating neighbour position w.r.t candidate\n",
    "                    neh['x'] = (((x1_neh + x2_neh) / 2) / width) - cd['x']\n",
    "                    neh['y'] = (((y1_neh + y2_neh) / 2) / height) - cd['y']\n",
    "                    neighbours.append(neh)\n",
    "                cd['neighbours'] = neighbours\n",
    "                annotations[cls][i] = cd\n",
    "    except Exception:\n",
    "        trace = traceback.format_exc()\n",
    "        print(\"Error in normalizing position: %s : %s\" % (trace, trace))\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg_nums(all_words):\n",
    "    reg_nums = []\n",
    "    reg_no_re = r'^[0-9a-zA-Z-:]+$'\n",
    "    for word in all_words:\n",
    "        if not re.search('\\d', word['text']):\n",
    "            continue\n",
    "        if len(word['text']) < 4:\n",
    "            continue\n",
    "        result = re.findall(reg_no_re, word['text'])\n",
    "        if result:\n",
    "            reg_nums.append({\n",
    "                'text': word['text'],\n",
    "                'x1': word['x1'],\n",
    "                'y1': word['y1'],\n",
    "                'x2': word['x2'],\n",
    "                'y2': word['y2']\n",
    "            })\n",
    "\n",
    "    return reg_nums\n",
    "\n",
    "def get_candidates(data):\n",
    "        all_words = []  \n",
    "\n",
    "        element_width = int(data['ocr']['pages'][0]['dimension']['width'])\n",
    "        element_height = int(data['ocr']['pages'][0]['dimension']['height'])\n",
    "\n",
    "        for token in data['ocr']['pages'][0]['tokens']:\n",
    "            if token['text'].strip() != \"\":\n",
    "                all_words.append({\n",
    "                    'text': token['text'],\n",
    "                    'x1': int(round(float(token['bbox'][1])*element_width)),\n",
    "                    'y1': int(round(float(token['bbox'][2])*element_height)),\n",
    "                    'x2': int(round(float(token['bbox'][3])*element_width)),\n",
    "                    'y2': int(round(float(token['bbox'][4])*element_height))})\n",
    "        text = ' '.join([word['text'].strip() for word in all_words])\n",
    "\n",
    "        try:\n",
    "            reg_num_candidates = get_reg_nums(all_words)\n",
    "        except Exception as e:\n",
    "            reg_num_candidates = []\n",
    "        # try:\n",
    "        #     reg_name_candidates = get_reg_names(data)\n",
    "        # except Exception as e:\n",
    "        #     reg_name_candidates = []\n",
    "\n",
    "        candidate_data = {\n",
    "            'registration_num': reg_num_candidates\n",
    "            # 'registrant_name': reg_name_candidates\n",
    "            # 'total': total_amount_candidates\n",
    "        }\n",
    "        return candidate_data\n",
    "\n",
    "def attach_neighbour(width, height, data, candidates):\n",
    "            \n",
    "    words = []\n",
    "\n",
    "    for token in data['ocr']['pages'][0]['tokens']:\n",
    "        if token['text'].strip() != \"\":\n",
    "            words.append({\n",
    "                'text': token['text'],\n",
    "                'x1': int(round(float(token['bbox'][1])*width)),\n",
    "                'y1': int(round(float(token['bbox'][2])*height)),\n",
    "                'x2': int(round(float(token['bbox'][3])*width)),\n",
    "                'y2': int(round(float(token['bbox'][4])*height))})\n",
    "    \n",
    "    x_offset = int(width * 0.1)\n",
    "    y_offset = int(height * 0.1)\n",
    "\n",
    "    for cls, both_cads in candidates.items():\n",
    "        for cad in both_cads:\n",
    "            neighbours = Neighbour.find_neighbour(cad, words, x_offset, y_offset, width, height)\n",
    "            cad['neighbours'] = neighbours\n",
    "    return candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shaur\\\\Desktop\\\\Glean_Implementation\\\\vrdu-main\\\\vrdu-main\\\\registration-form\\\\main\\\\pngs\\\\20110415_Podesta Group, Inc._Glassco, Timothy_Short-Form_1.png'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(config.IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "image = cv2.imread(str(config.IMAGE_PATH))\n",
    "height, width, _ = image.shape\n",
    "\n",
    "with open(config.IMAGE_OCR_PATH) as f:\n",
    "    ocr_results = json.load(f)\n",
    "vocab, class_mapping = load_saved_vocab(r\"C:\\Users\\shaur\\Desktop\\Glean_Implementation\\utils\\output\\cached_data_val.pickle\")\n",
    "candidates = get_candidates(ocr_results)\n",
    "candidates_with_neighbours = attach_neighbour(width, height, ocr_results, candidates)\n",
    "\n",
    "annotation = normalize_coordinates(candidates_with_neighbours, width, height)\n",
    "_data = parse_input(annotation, class_mapping, config.NEIGHBOURS, vocab)\n",
    "field_ids, candidate_cords, neighbours, neighbour_cords = _data\n",
    "rlie = torch.load(r\"C:\\Users\\shaur\\Desktop\\Glean_Implementation\\utils\\output\\model.pth\")\n",
    "rlie = rlie.to(device)\n",
    "field_ids = field_ids.to(device)\n",
    "candidate_cords = candidate_cords.to(device)\n",
    "neighbours = neighbours.to(device)\n",
    "neighbour_cords = neighbour_cords.to(device)\n",
    "field_idx_candidate = np.argmax(field_ids.detach().to('cpu').numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    rlie.eval()\n",
    "    val_outputs = rlie(field_ids, candidate_cords, neighbours, neighbour_cords, None)\n",
    "val_outputs = val_outputs.to('cpu').numpy()\n",
    "out = {cl: np.argmax(val_outputs[np.where(field_idx_candidate == cl)]) for cl in np.unique(field_idx_candidate)}\n",
    "true_candidate_color = (0, 255, 0)\n",
    "output_candidates = {}\n",
    "output_image = image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (key, value) in enumerate(candidates.items()):\n",
    "    if idx in out:\n",
    "        candidate_idx = out[idx]\n",
    "        cand = candidates[key][candidate_idx]\n",
    "        output_candidates[key] = cand['text']\n",
    "        cand_coords = [cand['x1'], cand['y1'], cand['x2'], cand['y2']]\n",
    "        cv2.rectangle(output_image, (cand_coords[0], cand_coords[1]), (cand_coords[2], cand_coords[3]),\n",
    "                        true_candidate_color, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'registration_num': '5926\\n'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "  \n",
    "# Window name in which image is displayed \n",
    "window_name = 'image'\n",
    "  \n",
    "# Using cv2.imshow() method \n",
    "# Displaying the image \n",
    "cv2.imshow(window_name, output_image) \n",
    "  \n",
    "# waits for user to press any key \n",
    "# (this is necessary to avoid Python kernel form crashing) \n",
    "cv2.waitKey(0) \n",
    "  \n",
    "# closing all open windows \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
